{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2FdH-1WoGui"
      },
      "source": [
        "# <font color=slateblue>**Importing Neccessary Libraries**</font> #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cWXRV-moJPC"
      },
      "source": [
        "import zipfile\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from numpy import linalg as LA\n",
        "import os, fnmatch, glob\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "import random\n",
        "import matplotlib.image as mpImg\n",
        "import os\n",
        "import pandas as pd\n",
        "from glob import glob   \n",
        "from matplotlib import pyplot as plt \n",
        "import cv2\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K-iVwhBoK8u"
      },
      "source": [
        "# <font color=slateblue>**Neccessary Functions**</font> #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUpy9UWyioTZ"
      },
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4mq2g0zGFyr"
      },
      "source": [
        "def parseAgeSexEthnicity(address):\n",
        "  splited = address.split('_')\n",
        "  age = splited[0]\n",
        "  age = age.replace('/content/drive/MyDrive/DeepNew/DataSetUnzip/UTKFace/', '')\n",
        "  sex = splited[1]\n",
        "  ethnicity = splited[2]\n",
        "  validCaption = (age.isdigit() and sex.isdigit() and ethnicity.isdigit())\n",
        "  return age, sex, ethnicity, validCaption"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v27MuWhdibsH"
      },
      "source": [
        "def loadImagesDirectory(directories, size = -1):\n",
        "  _image = []; _age = [];  _sex = []\n",
        "  _ethnicity = []\n",
        "  addr_files = directories\n",
        "  for addr in addr_files:\n",
        "    age, sex, ethnicity, validCaption = parseAgeSexEthnicity(address = addr)\n",
        "    if validCaption:\n",
        "      _age.append(int(age))\n",
        "      _sex.append(int(sex))\n",
        "      _ethnicity.append(int(ethnicity))\n",
        "      tmp_image = cv2.imread(addr)\n",
        "      _image.append(np.asarray(tmp_image))\n",
        "    else:\n",
        "      print('Age: ', age, 'Sex: ', sex, 'Ethnicity: ', ethnicity)\n",
        "    if len(_image) == size:\n",
        "      break\n",
        "  dataR = {'Image':np.asarray(_image), 'Age': np.asarray(_age), 'Sex':np.asarray(_sex), 'Ethnicity': np.asarray(_ethnicity)}\n",
        "  return dataR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-68zVT-Ti5nq"
      },
      "source": [
        "def flatten(dataSet):\n",
        "  dataSet = np.asarray(dataSet)\n",
        "  shapeData = np.shape(dataSet)\n",
        "  dim = 1\n",
        "  for i in range(1, len(shapeData)): dim = dim*shapeData[i]\n",
        "  dataSetFlatten = dataSet.reshape(shapeData[0], dim )\n",
        "  return dataSetFlatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPRBDtdthg96"
      },
      "source": [
        "def pcaNormalizer_directory(n_comp, dataDirectory, sizeData):\n",
        "  addr_files = sorted(glob(dataDirectory))\n",
        "  random.shuffle(addr_files)\n",
        "  dataSet = loadImagesDirectory(directories = addr_files, size = sizeData) \n",
        "  dataSet = dataSet['Image']\n",
        "  dataSetFlatten = flatten(dataSetImg)\n",
        "  print(\"**** \",np.shape(dataSetFlatten[0:2]))\n",
        "  #normalizer = Normalizer().fit(dataSetFlatten[0:1000]) \n",
        "  normalizer = StandardScaler().fit(dataSetFlatten)\n",
        "  dataSetFlatten = normalizer.transform(dataSetFlatten)\n",
        "  pcaTrans = PCA(n_components = n_comp)\n",
        "  pcaTrans.fit(dataSetFlatten) \n",
        "  return  pcaTrans, normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqKYtlINn4Qn"
      },
      "source": [
        "def prep_data(dataDirectory , pcaTransform, segmentSize, normalizerTrans):\n",
        "  addr_files = sorted(glob(dataDirectory))\n",
        "  random.shuffle(addr_files)\n",
        "  cnt = 0\n",
        "  for addr_files_batch in batch(addr_files, segmentSize):\n",
        "    dataSet = loadImagesDirectory(directories = addr_files_batch)\n",
        "    dataSetImg = dataSet['Image']\n",
        "    dataSetFlatten = flatten(dataSetImg)\n",
        "    dataSetFlatten = normalizerTrans.transform(dataSetFlatten)\n",
        "    transformedData = pcaTransform.transform(dataSetFlatten)\n",
        "    df = pd.DataFrame(np.asarray(transformedData))\n",
        "    df['Age'] = dataSet['Age']\n",
        "    df['Sex'] = dataSet['Sex']\n",
        "    df['Ethnicity'] = dataSet['Ethnicity']\n",
        "    df.to_csv(r'/content/drive/MyDrive/DeepNew/RedDimData7/Segment{0}.csv'.format(cnt), index = False)\n",
        "    cnt +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IWS6wqXotlE"
      },
      "source": [
        "# <font color=slateblue>**Train Net and Test that**</font> #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6KkAe2ujWXC"
      },
      "source": [
        "addr_filesI =  '/content/drive/MyDrive/DeepNew/DataSetUnzip/UTKFace/*.jpg'\n",
        "pcaTrans, normalizer = pcaNormalizer_directory(n_comp = 128, dataDirectory = addr_filesI, sizeData = 4000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp7iPEIf32kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6829a213-84d9-478c-9d76-83db47d7e2b8"
      },
      "source": [
        "prep_data(dataDirectory = addr_filesI , pcaTransform = pcaTrans, segmentSize = 1000, normalizerTrans = normalizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Age:  39 Sex:  1 Ethnicity:  20170116174525125.jpg.chip.jpg\n",
            "Age:  61 Sex:  1 Ethnicity:  20170109150557335.jpg.chip.jpg\n",
            "Age:  61 Sex:  1 Ethnicity:  20170109142408075.jpg.chip.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}